{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='logo_DH.png' align='left' width=35%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grupo 2\n",
    "### Integrantes:\n",
    "* Alejandro Fracchia  \n",
    "* Eugenia Perotti \n",
    "* Gastón Ortiz\n",
    "* Matias Formica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sección 1:\n",
    "* [Importacion de librerias y primer analisis](#importacion)\n",
    "* [Detección y eliminación de duplicados](#duplicados)\n",
    "\n",
    "#### Sección 2:\n",
    "* [Arreglo de columnas referidas a la localización](#geonamesid)\n",
    "    * [Campos de Coordenadas: lat, lon y lat-lon](#latlon)\n",
    "    * [Columnas descriptivas de ubicación](#ubicacion)\n",
    "    * [Valores faltantes](#regexlat)\n",
    "* [Arreglo de columnas referidas a price](#price)\n",
    "    * [Expresiones regulares para precios en dolares](#regex)\n",
    "    * [Expresiones regulares para precios en pesos](#pesos)\n",
    "* [Arreglo de columna Rooms](#ambientes)\n",
    "* [Arreglo de columna Floor](#floor)\n",
    "* [Arreglo de columnas referidas a los metros cuadrados](#m2)\n",
    "* [Creación de columna Pileta](#pileta)\n",
    "* [Creación de la columna Cochera](#cochera)\n",
    "* [Creación de las amenities](#amenities)\n",
    "\n",
    "#### Sección 3:\n",
    "* [Matriz de correlación](#matriz)\n",
    "* [Graficos](#graficos)\n",
    "    * [Variables Numericas](#numericas)\n",
    "    * [Variables Categoricas](#categoricas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"importacion\"></a>\n",
    "## Importacion de librería y primer análisis del data_original set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importo librerias que voy a usar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "pd.set_option('display.max_columns', None)\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leo el data_original set\n",
    "data_original = pd.read_csv(\"../properati.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121220, 26)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# veo el tamaño del data_original set\n",
    "data_original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# veo porcentaje de nulos y agrego nuevas columnas al data_original frame que voy a modificar mas tarde\n",
    "data_original['price_dolar'] = data_original['price_aprox_usd'].copy()\n",
    "data_original[\"ambientes\"] = data_original['rooms'].copy()\n",
    "data_original[\"price_m2_dolar\"] = data_original['price_usd_per_m2'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                    0.000000\n",
       "operation                     0.000000\n",
       "property_type                 0.000000\n",
       "place_name                    0.000190\n",
       "place_with_parent_names       0.000000\n",
       "country_name                  0.000000\n",
       "state_name                    0.000000\n",
       "geonames_id                   0.154405\n",
       "lat-lon                       0.425260\n",
       "lat                           0.425260\n",
       "lon                           0.425260\n",
       "price                         0.168372\n",
       "currency                      0.168380\n",
       "price_aprox_local_currency    0.168372\n",
       "price_aprox_usd               0.168372\n",
       "surface_total_in_m2           0.324435\n",
       "surface_covered_in_m2         0.164222\n",
       "price_usd_per_m2              0.433947\n",
       "price_per_m2                  0.276869\n",
       "floor                         0.934837\n",
       "rooms                         0.609058\n",
       "expenses                      0.882346\n",
       "properati_url                 0.000000\n",
       "description                   0.000016\n",
       "title                         0.000000\n",
       "image_thumbnail               0.025672\n",
       "price_dolar                   0.168372\n",
       "ambientes                     0.609058\n",
       "price_m2_dolar                0.433947\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pct_nulos(df):\n",
    "    nulos = df.isnull().sum() / df.shape[0]\n",
    "    return nulos\n",
    "nulos_original = pct_nulos(data_original)\n",
    "nulos_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'operation', 'property_type', 'place_name',\n",
       "       'place_with_parent_names', 'country_name', 'state_name', 'geonames_id',\n",
       "       'lat-lon', 'lat', 'lon', 'price', 'currency',\n",
       "       'price_aprox_local_currency', 'price_aprox_usd', 'surface_total_in_m2',\n",
       "       'surface_covered_in_m2', 'price_usd_per_m2', 'price_per_m2', 'floor',\n",
       "       'rooms', 'expenses', 'properati_url', 'description', 'title',\n",
       "       'image_thumbnail', 'price_dolar', 'ambientes', 'price_m2_dolar'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_original.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>price_aprox_local_currency</th>\n",
       "      <th>price_aprox_usd</th>\n",
       "      <th>surface_total_in_m2</th>\n",
       "      <th>surface_covered_in_m2</th>\n",
       "      <th>price_usd_per_m2</th>\n",
       "      <th>price_per_m2</th>\n",
       "      <th>floor</th>\n",
       "      <th>rooms</th>\n",
       "      <th>expenses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.008100e+05</td>\n",
       "      <td>1.008100e+05</td>\n",
       "      <td>1.008100e+05</td>\n",
       "      <td>81892.000000</td>\n",
       "      <td>101313.000000</td>\n",
       "      <td>68617.000000</td>\n",
       "      <td>8.765800e+04</td>\n",
       "      <td>7899.000000</td>\n",
       "      <td>47390.000000</td>\n",
       "      <td>1.426200e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.685259e+05</td>\n",
       "      <td>4.229397e+06</td>\n",
       "      <td>2.397006e+05</td>\n",
       "      <td>233.795328</td>\n",
       "      <td>133.050181</td>\n",
       "      <td>2160.086916</td>\n",
       "      <td>6.912216e+03</td>\n",
       "      <td>17.452336</td>\n",
       "      <td>3.080840</td>\n",
       "      <td>5.009234e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.260101e+06</td>\n",
       "      <td>6.904714e+06</td>\n",
       "      <td>3.913239e+05</td>\n",
       "      <td>1782.222147</td>\n",
       "      <td>724.351479</td>\n",
       "      <td>2759.288621</td>\n",
       "      <td>2.837864e+04</td>\n",
       "      <td>120.243621</td>\n",
       "      <td>1.860773</td>\n",
       "      <td>1.204403e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.510204e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.100000e+05</td>\n",
       "      <td>1.583309e+06</td>\n",
       "      <td>8.973388e+04</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1218.181818</td>\n",
       "      <td>1.550000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.850000e+05</td>\n",
       "      <td>2.558452e+06</td>\n",
       "      <td>1.450000e+05</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>1800.000000</td>\n",
       "      <td>2.213115e+03</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.200000e+05</td>\n",
       "      <td>4.675792e+06</td>\n",
       "      <td>2.650000e+05</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>2486.411765</td>\n",
       "      <td>3.355549e+03</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.500000e+08</td>\n",
       "      <td>8.212711e+08</td>\n",
       "      <td>4.654544e+07</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>187000.000000</td>\n",
       "      <td>206333.333333</td>\n",
       "      <td>4.000000e+06</td>\n",
       "      <td>3150.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.000150e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              price  price_aprox_local_currency  price_aprox_usd  \\\n",
       "count  1.008100e+05                1.008100e+05     1.008100e+05   \n",
       "mean   4.685259e+05                4.229397e+06     2.397006e+05   \n",
       "std    2.260101e+06                6.904714e+06     3.913239e+05   \n",
       "min    0.000000e+00                0.000000e+00     0.000000e+00   \n",
       "25%    1.100000e+05                1.583309e+06     8.973388e+04   \n",
       "50%    1.850000e+05                2.558452e+06     1.450000e+05   \n",
       "75%    4.200000e+05                4.675792e+06     2.650000e+05   \n",
       "max    6.500000e+08                8.212711e+08     4.654544e+07   \n",
       "\n",
       "       surface_total_in_m2  surface_covered_in_m2  price_usd_per_m2  \\\n",
       "count         81892.000000          101313.000000      68617.000000   \n",
       "mean            233.795328             133.050181       2160.086916   \n",
       "std            1782.222147             724.351479       2759.288621   \n",
       "min               0.000000               0.000000          0.600000   \n",
       "25%              50.000000              45.000000       1218.181818   \n",
       "50%              84.000000              75.000000       1800.000000   \n",
       "75%             200.000000             150.000000       2486.411765   \n",
       "max          200000.000000          187000.000000     206333.333333   \n",
       "\n",
       "       price_per_m2        floor         rooms      expenses  \n",
       "count  8.765800e+04  7899.000000  47390.000000  1.426200e+04  \n",
       "mean   6.912216e+03    17.452336      3.080840  5.009234e+03  \n",
       "std    2.837864e+04   120.243621      1.860773  1.204403e+05  \n",
       "min    1.510204e+00     1.000000      1.000000  1.000000e+00  \n",
       "25%    1.550000e+03     1.000000      2.000000  1.000000e+03  \n",
       "50%    2.213115e+03     3.000000      3.000000  2.000000e+03  \n",
       "75%    3.355549e+03     6.000000      4.000000  4.000000e+03  \n",
       "max    4.000000e+06  3150.000000     32.000000  1.000150e+07  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Algunas medidas de disperción de los datos\n",
    "data_original[['price', 'price_aprox_local_currency','price_aprox_usd', 'surface_total_in_m2',\\\n",
    "       'surface_covered_in_m2', 'price_usd_per_m2', 'price_per_m2', 'floor',\\\n",
    "       'rooms', 'expenses']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"duplicados\"></a>\n",
    "## Detección y eliminación de duplicados.\n",
    "Tuvimos varios criterios para eliminar filas duplicadas, para no borrar ninguna que no lo sea.\n",
    "Las columnas que elegimos para que una fila se considere duplicado son \"property_type\",\"place_name\",\"geonames_id\",\"lat-lon\",\"price\",\"surface_total_in_m2\",\"surface_covered_in_m2\",\"description\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cantidad de duplicados a borrar 6069\n",
      "si saco la descripcion, podria borrar 13873\n"
     ]
    }
   ],
   "source": [
    "# vemos cuantos duplicados voy a borrar \n",
    "desc_dupl = data_original.duplicated(subset=[\"property_type\",\"place_name\",\"geonames_id\",\"lat-lon\",\"price\",\"surface_total_in_m2\",\"surface_covered_in_m2\",\"description\"])\n",
    "print(\"cantidad de duplicados a borrar\", desc_dupl.sum())\n",
    "sindesc_dupl = data_original.duplicated(subset=[\"property_type\",\"place_name\",\"geonames_id\",\"lat-lon\",\"price\",\"surface_total_in_m2\",\"surface_covered_in_m2\"])\n",
    "print(\"si saco la descripcion, podria borrar\",sindesc_dupl.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((115149, 29), (121218, 29))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# borramos los duplicados, que en total son 6069.\n",
    "data_original.dropna(subset=[\"description\"],inplace=True)\n",
    "data = data_original.drop_duplicates(subset=[\"property_type\",\"place_name\",\"geonames_id\",\"lat-lon\",\"price\",\"surface_total_in_m2\",\"surface_covered_in_m2\",\"description\"],keep=\"first\")\n",
    "pct_nulos1 = data.isnull().sum() / data.shape[0]\n",
    "data.shape,data_original.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"geonamesid\"></a>\n",
    "## Arreglo de columnas referidas a la geolocalización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay varios campos que intervienen en la **geolocalización**. Los más útiles son **lan** y **lon** porque nos dan la ubicación exacta de la propiedad. El problema es que tienen un porcentaje alto de nulos, por lo que el objetivo va a ser tratar de inducir estos valores. \n",
    "\n",
    "Los campos que vamos a evaluar para definir una estrategia de imputación, serán: \n",
    "* **lat-lon:** concatenación de latitud y longitud.\n",
    "* **lat:** latitud.\n",
    "* **lon:** longitud.\n",
    "* **place_name:** localidad o barrio.\n",
    "* **place_with_parent_names:** concatenación de ubicaciones.\n",
    "* **country_name:** país.\n",
    "* **state_name:** provincia o partido.\n",
    "* **geonames_id:** identificador de ubicación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Campos de Coordenadas: lat, lon y lat-lon.\n",
    "Hay tres campos de coordenadas: **lat, lon** y **lat-lon**. \n",
    "\n",
    "Revisando qué información tienen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat-lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-34.661824</td>\n",
       "      <td>-58.508839</td>\n",
       "      <td>-34.6618237,-58.5088387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-34.903883</td>\n",
       "      <td>-57.964330</td>\n",
       "      <td>-34.9038831,-57.9643295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-34.652262</td>\n",
       "      <td>-58.522982</td>\n",
       "      <td>-34.6522615,-58.5229825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lat        lon                  lat-lon\n",
       "0 -34.661824 -58.508839  -34.6618237,-58.5088387\n",
       "1 -34.903883 -57.964330  -34.9038831,-57.9643295\n",
       "2 -34.652262 -58.522982  -34.6522615,-58.5229825"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['lat','lon','lat-lon']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lat        47745\n",
       "lon        47745\n",
       "lat-lon    47745\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cantidad de nulos\n",
    "data[['lat','lon','lat-lon']].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lat        0.41\n",
       "lon        0.41\n",
       "lat-lon    0.41\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Porcentaje de nulos\n",
    "round(data[['lat','lon','lat-lon']].isnull().sum() / data.shape[0],2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple vista, pareciera ser que **lat-lon** tiene la misma información que **lat** y **lon**, con un decimal adicional.\n",
    "\n",
    "Para comprobar si esto efectivamente es así, separaremos **lat-lon** en dos columnas y luego compararemos a cada una contra **lat** y **lon**, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad no nulos lati: 67404\n",
      "Cantidad no nulos lat: 67404\n",
      "Cantidad no nulos longi: 67404\n",
      "Cantidad no nulos lon: 67404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\dhdsblend\\lib\\site-packages\\ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\ProgramData\\Anaconda3\\envs\\dhdsblend\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat-lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat-lon_latitud</th>\n",
       "      <th>lat-lon_longitud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-34.6618237,-58.5088387</td>\n",
       "      <td>-34.661824</td>\n",
       "      <td>-58.508839</td>\n",
       "      <td>-34.661824</td>\n",
       "      <td>-58.508839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-34.9038831,-57.9643295</td>\n",
       "      <td>-34.903883</td>\n",
       "      <td>-57.964330</td>\n",
       "      <td>-34.903883</td>\n",
       "      <td>-57.964329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-34.6522615,-58.5229825</td>\n",
       "      <td>-34.652262</td>\n",
       "      <td>-58.522982</td>\n",
       "      <td>-34.652262</td>\n",
       "      <td>-58.522982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   lat-lon        lat        lon  lat-lon_latitud  \\\n",
       "0  -34.6618237,-58.5088387 -34.661824 -58.508839       -34.661824   \n",
       "1  -34.9038831,-57.9643295 -34.903883 -57.964330       -34.903883   \n",
       "2  -34.6522615,-58.5229825 -34.652262 -58.522982       -34.652262   \n",
       "\n",
       "   lat-lon_longitud  \n",
       "0        -58.508839  \n",
       "1        -57.964329  \n",
       "2        -58.522982  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Separar lat-lon en lat y lon.\n",
    "lati = data['lat-lon'].apply(lambda x: x if x is np.NaN else float(x.split(\",\")[0]))\n",
    "longi = data['lat-lon'].apply(lambda x: x if x is np.NaN else float(x.split(\",\")[1]))\n",
    "\n",
    "# 2. Comparar contra lan para ver si son iguales.\n",
    "lati_notnulls = lati.notnull()\n",
    "lat_notnulls = data['lat'].notnull()\n",
    "print('Cantidad no nulos lati:', lati_notnulls.sum())\n",
    "print('Cantidad no nulos lat:', lat_notnulls.sum())\n",
    "mask_noiguales_latitud = lati_notnulls != lat_notnulls\n",
    "\n",
    "data.loc[mask_noiguales_latitud, :]\n",
    "\n",
    "# 3. Comparar contra lon para ver si son iguales.\n",
    "longi_notnulls = longi.notnull()\n",
    "lon_notnulls = data['lon'].notnull()\n",
    "print('Cantidad no nulos longi:', longi_notnulls.sum())\n",
    "print('Cantidad no nulos lon:', lon_notnulls.sum())\n",
    "mask_noiguales_longitud = longi_notnulls != lon_notnulls\n",
    "data.loc[mask_noiguales_longitud, :]\n",
    "\n",
    "# 4. Confirmación visual.\n",
    "data['lat-lon_longitud'] = longi\n",
    "data['lat-lon_latitud'] = lati\n",
    "\n",
    "data[['lat-lon', 'lat', 'lon' , 'lat-lon_latitud','lat-lon_longitud']].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos concluir que el campo **lat-lon** tiene la misma información que **lat** y **lon** separadamente. \n",
    "\n",
    "Por una cuestión de practicidad es preferible tener estos campos por separado, y por lo tanto se puede prescindir de esta columna."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:red; font-size:20px;\"> COMENTARIOS</p>\n",
    "\n",
    "\n",
    "Sobre la celda de aquí arriba. \n",
    "\n",
    "* En lugar de hacer un apply y evaluar con una función lambda si cada elemento si es nulo, filtrar con una máscara los elementos nulos y luego hacer un apply sobre todos los elementos. Ejemplo:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay diferencias entre lat y lat-lon?  False\n",
      "Hay diferencias entre lon y lat-lon?  False\n"
     ]
    }
   ],
   "source": [
    "data_ah=data.copy();\n",
    "\n",
    "mask=data_ah['lat-lon'].notnull();\n",
    "\n",
    "latlon=data_ah.loc[mask,'lat-lon'].apply(lambda x: x.split(\",\"))\n",
    "lati=latlon.apply(lambda x: np.float(x[0]))\n",
    "longi=latlon.apply(lambda x: np.float(x[1]))\n",
    "\n",
    "print('Hay diferencias entre lat y lat-lon? ', ( np.round(data_ah.loc[mask,'lat'],4)!=np.round(lati,4) ).any() )\n",
    "print('Hay diferencias entre lon y lat-lon? ', ( np.round(data_ah.loc[mask,'lon'],4)!=np.round(longi,4) ).any() )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ubicacion\"></a>\n",
    "### Columnas descriptivas de ubicación: place_name, place_with_parent_names, country_name y state_name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>place_name</th>\n",
       "      <th>place_with_parent_names</th>\n",
       "      <th>country_name</th>\n",
       "      <th>state_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mataderos</td>\n",
       "      <td>|Argentina|Capital Federal|Mataderos|</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Capital Federal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La Plata</td>\n",
       "      <td>|Argentina|Bs.As. G.B.A. Zona Sur|La Plata|</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Bs.As. G.B.A. Zona Sur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mataderos</td>\n",
       "      <td>|Argentina|Capital Federal|Mataderos|</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Capital Federal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  place_name                      place_with_parent_names country_name  \\\n",
       "0  Mataderos        |Argentina|Capital Federal|Mataderos|    Argentina   \n",
       "1   La Plata  |Argentina|Bs.As. G.B.A. Zona Sur|La Plata|    Argentina   \n",
       "2  Mataderos        |Argentina|Capital Federal|Mataderos|    Argentina   \n",
       "\n",
       "               state_name  \n",
       "0         Capital Federal  \n",
       "1  Bs.As. G.B.A. Zona Sur  \n",
       "2         Capital Federal  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['place_name', 'place_with_parent_names', 'country_name', 'state_name']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "place_name                 23\n",
       "place_with_parent_names     0\n",
       "country_name                0\n",
       "state_name                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['place_name', 'place_with_parent_names', 'country_name', 'state_name']].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En estas columnas aparentemente no hay mayores problemas de nulos. Sólo **place_name** tiene 23 elementos a los que les falta valor. \n",
    "\n",
    "Revisemos un poco más estos datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros no nulos: 115126\n",
      "Registros nulos: 23\n"
     ]
    }
   ],
   "source": [
    "mask_place_name_nulos = data.place_name.isnull()\n",
    "mask_place_name_no_nulos = data.place_name.notnull()\n",
    "print('Registros no nulos:', data.loc[mask_place_name_no_nulos,'place_name'].shape[0])\n",
    "print('Registros nulos:', data.loc[mask_place_name_nulos,'place_name'].shape[0])\n",
    "# data.loc[mask_place_name_nulos].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al evaluar los datos se ve que ese dato está faltando y no es posible deducirlo. Como son sólo 23 registros, podríamos eliminarlos de la serie.\n",
    "\n",
    "Nos fijamos cómo está el resto de los campos cuando estos valores son nulos, para estar seguros de no estar tirando información valiosa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>price_aprox_local_currency</th>\n",
       "      <th>price_aprox_usd</th>\n",
       "      <th>price_usd_per_m2</th>\n",
       "      <th>price_per_m2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6489</th>\n",
       "      <td>650000.0</td>\n",
       "      <td>11468925.0</td>\n",
       "      <td>650000.0</td>\n",
       "      <td>2708.333333</td>\n",
       "      <td>2708.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10201</th>\n",
       "      <td>535000.0</td>\n",
       "      <td>9439807.5</td>\n",
       "      <td>535000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1783.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11451</th>\n",
       "      <td>550000.0</td>\n",
       "      <td>9704475.0</td>\n",
       "      <td>550000.0</td>\n",
       "      <td>253.456221</td>\n",
       "      <td>2037.037037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14839</th>\n",
       "      <td>480000.0</td>\n",
       "      <td>8469360.0</td>\n",
       "      <td>480000.0</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18622</th>\n",
       "      <td>1297000.0</td>\n",
       "      <td>22884916.5</td>\n",
       "      <td>1297000.0</td>\n",
       "      <td>3814.705882</td>\n",
       "      <td>3814.705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21922</th>\n",
       "      <td>440000.0</td>\n",
       "      <td>7763580.0</td>\n",
       "      <td>440000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23664</th>\n",
       "      <td>480000.0</td>\n",
       "      <td>8469360.0</td>\n",
       "      <td>480000.0</td>\n",
       "      <td>1632.653061</td>\n",
       "      <td>1632.653061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24722</th>\n",
       "      <td>530000.0</td>\n",
       "      <td>9351585.0</td>\n",
       "      <td>530000.0</td>\n",
       "      <td>1677.215190</td>\n",
       "      <td>1962.962963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38856</th>\n",
       "      <td>1350000.0</td>\n",
       "      <td>23820075.0</td>\n",
       "      <td>1350000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2454.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45970</th>\n",
       "      <td>95000.0</td>\n",
       "      <td>1676227.5</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>1727.272727</td>\n",
       "      <td>3518.518519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46642</th>\n",
       "      <td>1470000.0</td>\n",
       "      <td>25937415.0</td>\n",
       "      <td>1470000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53130</th>\n",
       "      <td>630000.0</td>\n",
       "      <td>11116035.0</td>\n",
       "      <td>630000.0</td>\n",
       "      <td>630.000000</td>\n",
       "      <td>1702.702703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55306</th>\n",
       "      <td>470000.0</td>\n",
       "      <td>8292915.0</td>\n",
       "      <td>470000.0</td>\n",
       "      <td>1850.393701</td>\n",
       "      <td>2303.921569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57703</th>\n",
       "      <td>650000.0</td>\n",
       "      <td>11468925.0</td>\n",
       "      <td>650000.0</td>\n",
       "      <td>2826.086957</td>\n",
       "      <td>2826.086957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57759</th>\n",
       "      <td>580000.0</td>\n",
       "      <td>10233810.0</td>\n",
       "      <td>580000.0</td>\n",
       "      <td>1611.111111</td>\n",
       "      <td>1611.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57764</th>\n",
       "      <td>970000.0</td>\n",
       "      <td>17115165.0</td>\n",
       "      <td>970000.0</td>\n",
       "      <td>2282.352941</td>\n",
       "      <td>2480.818414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57793</th>\n",
       "      <td>760000.0</td>\n",
       "      <td>13409820.0</td>\n",
       "      <td>760000.0</td>\n",
       "      <td>3040.000000</td>\n",
       "      <td>3040.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58004</th>\n",
       "      <td>550000.0</td>\n",
       "      <td>9704475.0</td>\n",
       "      <td>550000.0</td>\n",
       "      <td>2067.669173</td>\n",
       "      <td>2391.304348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58037</th>\n",
       "      <td>590000.0</td>\n",
       "      <td>10410255.0</td>\n",
       "      <td>590000.0</td>\n",
       "      <td>1843.750000</td>\n",
       "      <td>1843.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59069</th>\n",
       "      <td>640000.0</td>\n",
       "      <td>11292480.0</td>\n",
       "      <td>640000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2580.645161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62411</th>\n",
       "      <td>340000.0</td>\n",
       "      <td>5999130.0</td>\n",
       "      <td>340000.0</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62413</th>\n",
       "      <td>419000.0</td>\n",
       "      <td>7393045.5</td>\n",
       "      <td>419000.0</td>\n",
       "      <td>1676.000000</td>\n",
       "      <td>2095.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63849</th>\n",
       "      <td>400000.0</td>\n",
       "      <td>7057800.0</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>2857.142857</td>\n",
       "      <td>2857.142857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           price  price_aprox_local_currency  price_aprox_usd  \\\n",
       "6489    650000.0                  11468925.0         650000.0   \n",
       "10201   535000.0                   9439807.5         535000.0   \n",
       "11451   550000.0                   9704475.0         550000.0   \n",
       "14839   480000.0                   8469360.0         480000.0   \n",
       "18622  1297000.0                  22884916.5        1297000.0   \n",
       "21922   440000.0                   7763580.0         440000.0   \n",
       "23664   480000.0                   8469360.0         480000.0   \n",
       "24722   530000.0                   9351585.0         530000.0   \n",
       "38856  1350000.0                  23820075.0        1350000.0   \n",
       "45970    95000.0                   1676227.5          95000.0   \n",
       "46642  1470000.0                  25937415.0        1470000.0   \n",
       "53130   630000.0                  11116035.0         630000.0   \n",
       "55306   470000.0                   8292915.0         470000.0   \n",
       "57703   650000.0                  11468925.0         650000.0   \n",
       "57759   580000.0                  10233810.0         580000.0   \n",
       "57764   970000.0                  17115165.0         970000.0   \n",
       "57793   760000.0                  13409820.0         760000.0   \n",
       "58004   550000.0                   9704475.0         550000.0   \n",
       "58037   590000.0                  10410255.0         590000.0   \n",
       "59069   640000.0                  11292480.0         640000.0   \n",
       "62411   340000.0                   5999130.0         340000.0   \n",
       "62413   419000.0                   7393045.5         419000.0   \n",
       "63849   400000.0                   7057800.0         400000.0   \n",
       "\n",
       "       price_usd_per_m2  price_per_m2  \n",
       "6489        2708.333333   2708.333333  \n",
       "10201               NaN   1783.333333  \n",
       "11451        253.456221   2037.037037  \n",
       "14839       2000.000000   2400.000000  \n",
       "18622       3814.705882   3814.705882  \n",
       "21922               NaN   2000.000000  \n",
       "23664       1632.653061   1632.653061  \n",
       "24722       1677.215190   1962.962963  \n",
       "38856               NaN   2454.545455  \n",
       "45970       1727.272727   3518.518519  \n",
       "46642               NaN  73500.000000  \n",
       "53130        630.000000   1702.702703  \n",
       "55306       1850.393701   2303.921569  \n",
       "57703       2826.086957   2826.086957  \n",
       "57759       1611.111111   1611.111111  \n",
       "57764       2282.352941   2480.818414  \n",
       "57793       3040.000000   3040.000000  \n",
       "58004       2067.669173   2391.304348  \n",
       "58037       1843.750000   1843.750000  \n",
       "59069               NaN   2580.645161  \n",
       "62411       2000.000000   2000.000000  \n",
       "62413       1676.000000   2095.000000  \n",
       "63849       2857.142857   2857.142857  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[mask_place_name_nulos, ['price','price_aprox_local_currency','price_aprox_usd','price_usd_per_m2','price_per_m2']]\n",
    "# Ver si se puede deducir place_name con la descripcion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como las columnas de precio tienen información, decidimos que es mejor no eliminarlos.\n",
    "\n",
    "Al revisar los datos que contiene **place_with_parent_names**, podemos ver que tiene datos que las otras tres columnas juntas no poseen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:red; font-size:20px;\"> COMENTARIOS</p>\n",
    "\n",
    "<p style=\"color:red; font-size:15px;\"> \n",
    "Bien, por otro lado tal vez la información de la ubicación esté en el campo de descripción, o sea deducible de las coordenadas lat-lon si estuvieran.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                |Argentina|Capital Federal|Mataderos|\n",
       "1          |Argentina|Bs.As. G.B.A. Zona Sur|La Plata|\n",
       "2                |Argentina|Capital Federal|Mataderos|\n",
       "3                  |Argentina|Capital Federal|Liniers|\n",
       "4    |Argentina|Buenos Aires Costa Atlántica|Mar de...\n",
       "5                  |Argentina|Entre Ríos|Gualeguaychú|\n",
       "6    |Argentina|Bs.As. G.B.A. Zona Norte|Vicente Ló...\n",
       "7                 |Argentina|Capital Federal|Belgrano|\n",
       "8                 |Argentina|Capital Federal|Belgrano|\n",
       "9                         |Argentina|Santa Fe|Rosario|\n",
       "Name: place_with_parent_names, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_original.place_with_parent_names.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a guardar estos datos en columnas separadas para futuros análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_place_with_parent_names = data.place_with_parent_names\n",
    "\n",
    "def limpiar_serie(serie):\n",
    "    parents_name_lista = []\n",
    "    for i in serie:\n",
    "        parent_name = i.split(\"|\")\n",
    "\n",
    "        #se elimina el primer elemento si está vacío\n",
    "        if (parent_name[0] != ''):\n",
    "            print(\"Elemento encontrado:\", parent_name[0])\n",
    "        else:\n",
    "            del parent_name[0]\n",
    "\n",
    "        #se elimina el último elemento si está vacío    \n",
    "        if (parent_name[-1] != ''):\n",
    "            print(\"Elemento encontrado:\", parent_name[-1])\n",
    "        else:\n",
    "            del parent_name[-1]\n",
    "\n",
    "        #Se imprime la lista limpia para chequear que no hayan quedado elementos vacíos\n",
    "        #print(parent_name)\n",
    "        parents_name_lista.append(parent_name)\n",
    "        \n",
    "    return parents_name_lista\n",
    "\n",
    "# Con la función definida obtenemos una lista con los elementos sin blancos\n",
    "parents_name_list = limpiar_serie(serie_place_with_parent_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad máxima de elementos es: 5\n"
     ]
    }
   ],
   "source": [
    "#se crea una cantidad de campos en base al valor máximo de len() \n",
    "#se recorren los elementos y, si no están nulos, se los va agregando a los campos \n",
    "longitud_maxima = 0\n",
    "\n",
    "for pn in parents_name_list:\n",
    "    if (len(pn) >= longitud_maxima):\n",
    "        longitud_maxima = len(pn)\n",
    "         \n",
    "print(\"La cantidad máxima de elementos es:\",longitud_maxima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True    115149\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compruebo si la primera posicion contiene al pais\n",
    "serie_parents_name = pd.Series(parents_name_list)\n",
    "pais_argentina = serie_parents_name.apply(lambda x: True if x[0] == 'Argentina' else False)\n",
    "pais_argentina.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Capital Federal                 30475\n",
       "Bs.As. G.B.A. Zona Norte        24538\n",
       "Bs.As. G.B.A. Zona Sur          13493\n",
       "Córdoba                         11455\n",
       "Buenos Aires Costa Atlántica     9874\n",
       "Santa Fe                         8960\n",
       "Bs.As. G.B.A. Zona Oeste         8941\n",
       "Buenos Aires Interior            2246\n",
       "Río Negro                         789\n",
       "Mendoza                           656\n",
       "Tucumán                           631\n",
       "Neuquén                           585\n",
       "Corrientes                        572\n",
       "Misiones                          404\n",
       "Entre Ríos                        356\n",
       "Salta                             276\n",
       "Chubut                            259\n",
       "San Luis                          245\n",
       "La Pampa                          153\n",
       "Chaco                              57\n",
       "San Juan                           40\n",
       "Formosa                            32\n",
       "Tierra Del Fuego                   31\n",
       "Catamarca                          27\n",
       "Jujuy                              26\n",
       "Santa Cruz                         20\n",
       "Santiago Del Estero                 4\n",
       "La Rioja                            4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compruebo que la posicion 1 contenga las pronvicias\n",
    "provincia = serie_parents_name.apply(lambda x: x[1])\n",
    "provincia.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La idea era crear las columnas nuevas necesarias con los valores nuevos que aparecen en la columna **place_with_parent_names** y que no estan en las columnas **place_name, country_name y state_name**. No se termino de completar por falta de tiempo. Se deja para un futuro analisis en el siguiente modulo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:red; font-size:20px;\"> COMENTARIOS</p>\n",
    "\n",
    "<p style=\"color:red; font-size:15px;\"> \n",
    "En lugar de hacer un loop que recorra los elementos de una serie, conviene usar el método apply.\n",
    "Les dejo unas pistas para achicar el código:\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>Capital Federal</td>\n",
       "      <td>Mataderos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>Bs.As. G.B.A. Zona Sur</td>\n",
       "      <td>La Plata</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>Capital Federal</td>\n",
       "      <td>Mataderos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0                       1          2    3    4\n",
       "0  Argentina         Capital Federal  Mataderos  NaN  NaN\n",
       "1  Argentina  Bs.As. G.B.A. Zona Sur   La Plata  NaN  NaN\n",
       "2  Argentina         Capital Federal  Mataderos  NaN  NaN"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask=data_ah['place_with_parent_names'].notnull();\n",
    "def split_places(x):\n",
    "    if x[0]=='|':\n",
    "        x=x[1:]\n",
    "    if x[-1]=='|':\n",
    "        x=x[:-1];\n",
    "    return x.split('|')\n",
    "serie_places=data_ah.loc[mask,'place_with_parent_names'].apply(split_places);\n",
    "places_df=serie_places.apply(pd.Series); # Este método es muy ineficiente, pero nos ahorra muchas lineas de código\n",
    "places_df.head(3) # Recuerden que para generar este dataframe filtraron los valores nulos en place_with_parent_names. Por eso tiene menos filas que 'data'\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"regexlat\"></a>\n",
    "### Se procede a completar los valores de las columnas **geonames_id** y **lat-lon** que contengan nulos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para completar los valores nulos, vamos a hacerlo por **place_name**. Agrupando este campo, cada place_name tiene un único **geonames_id**, por lo que si tenemos algun nulo en **geonames_id** que tenga place_name lo completaremos con el valor de **geonames_id** del que esté completo que tenga el mismo **place_name**.\n",
    "\n",
    "Para esto, vamos a:\n",
    "1. Agrupar los datos por **place_name**.\n",
    "2. Dentro de esa agrupación, buscar el campo **geonames_id** y hacer un value_counts.\n",
    "3. Despues se procedera a hacer un iterrows en el data_original frame para buscar los nulos de **geonames_id** que tengan **place_name**, y se procederá a completarlos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:red; font-size:20px;\"> COMENTARIOS</p>\n",
    "\n",
    "<p style=\"color:red; font-size:15px;\"> \n",
    "Guarda! en la celda de acá abajo NO están guardando los cambios en el dataframe. En cada iteración modifican una variable nueva 'row' que es independiente del dataframe.\n",
    "</br></br>\n",
    "Por otro lado, nuevamente están iterando sobre todas las filas y chequeando en cada caso que no contenga un valor nulo. Es mucho más eficiente usar una máscara booleana para identificar los campos no nulos y luego trabajar sobre estos.\n",
    "</br></br>\n",
    "Usen el método apply en lugar de hacer un for loop.\n",
    "</br></br>\n",
    "Más allá del código, tiene sentido imputar geonames_id cuando ya tienen el place_name? Lo entendería más si fuera al revés: conseguir el place_name dado el geoname_id\n",
    "</p>    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nulos antes: 18003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\dhdsblend\\lib\\site-packages\\pandas\\core\\indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\dhdsblend\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nulos despues: 13135\n",
      "Tiempo: 28.617125988006592\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t0=time.time()\n",
    "\n",
    "print('Nulos antes:',data['geonames_id'].isnull().sum())\n",
    "\n",
    "grupos_id = data.groupby(\"place_name\")[\"geonames_id\"].value_counts()\n",
    "contador = 0\n",
    "for index,row in data.iterrows():\n",
    "    if np.isnan(row.geonames_id):\n",
    "        try:\n",
    "            data.geonames_id.loc[index] = grupos_id.loc[row.place_name].index[0]\n",
    "        except:            \n",
    "            contador +=1\n",
    "contador\n",
    "\n",
    "print('Nulos despues:',data['geonames_id'].isnull().sum())\n",
    "\n",
    "t1=time.time()\n",
    "# \n",
    "print('Tiempo:',t1-t0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:red; font-size:15px;\"> \n",
    "Aquí tienen una modificación posible:\n",
    "</br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nulos antes: 18003\n",
      "Nulos despues: 13135\n",
      "Tiempo: 32.58415150642395\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Nulos antes:',data_ah['geonames_id'].isnull().sum());\n",
    "\n",
    "# t0=time.time();\n",
    "\n",
    "grupos_id = data_ah.groupby(\"place_name\")[\"geonames_id\"].value_counts();\n",
    "\n",
    "mask1=np.logical_and(data_ah['geonames_id'].isnull() , data_ah['place_name'].notnull());\n",
    "\n",
    "place_names_grupos_id=grupos_id.index.get_level_values('place_name');\n",
    "\n",
    "mask2=data_ah['place_name'].apply(lambda x: x in place_names_grupos_id);\n",
    "\n",
    "geonames_completables=np.logical_and(mask1,mask2);\n",
    "mask1.sum(),mask2.sum()\n",
    "\n",
    "data_ah['geonames_id']\n",
    "\n",
    "def imputacion_geonames_id(x):        \n",
    "    x['geonames_id']= grupos_id.loc[x['place_name']].index[0];\n",
    "    return x\n",
    "\n",
    "data_ah.loc[geonames_completables]=data_ah.loc[geonames_completables].apply(imputacion_geonames_id,axis=1);\n",
    "\n",
    "print('Nulos despues:',data_ah['geonames_id'].isnull().sum())\n",
    "\n",
    "t1=time.time();\n",
    "\n",
    "print('Tiempo:',t1-t0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparamos cantidad de nulos que tenemos ahora vs. la que teníamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de nulos antes: 18717\n",
      "Cantidad de nulos ahora: 13135\n"
     ]
    }
   ],
   "source": [
    "print(\"Cantidad de nulos antes:\",data_original.geonames_id.isnull().sum())\n",
    "print(\"Cantidad de nulos ahora:\",data.geonames_id.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47745"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grupos_id_latlon = data.groupby([\"place_name\",\"geonames_id\"])[\"lat-lon\"].value_counts()\n",
    "contador = 0\n",
    "for index,row in data.iterrows():\n",
    "    if row[\"lat-lon\"] is np.NaN:\n",
    "        try:\n",
    "            row[\"lat-lon\"] = grupos_id_latlon.loc[row.place_name].index[0][2]\n",
    "            row[\"lat\"] = grupos_id_latlon.loc[row.place_name].index[0][2].split(\",\")[0]\n",
    "            row[\"lon\"] = grupos_id_latlon.loc[row.place_name].index[0][2].split(\",\")[1]\n",
    "            print()\n",
    "            \n",
    "        except:\n",
    "            contador +=1\n",
    "contador\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de nulos antes: 51549\n",
      "Cantidad de nulos ahora: 47745\n"
     ]
    }
   ],
   "source": [
    "# Ya que las columnas lat-lon, lat, lon son iguales deberian tener la misma cantidad de nulos\n",
    "# Veo cuantos nulos me quedaron\n",
    "print(\"Cantidad de nulos antes:\",data_original[\"lat-lon\"].isnull().sum())\n",
    "print(\"Cantidad de nulos ahora:\",data[\"lat-lon\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"price\"></a>\n",
    "## Arreglo de columnas referidas al precio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay varios campos que intervienen en el precio o que tienen información pertinente que podemos extraer:\n",
    "\n",
    "* **price:** Precio original del aviso\n",
    "* **currency:** Moneda original del aviso (ARS, USD)\n",
    "* **price_aprox_local_currency:** Precio del aviso en moneda local (ARS)\n",
    "* **price_aprox_usd:** Precio aproximado en USD\n",
    "* **price_usd_per_m2:** Precio en USD/m²\n",
    "* **price_per_m2:** Precio por m²\n",
    "* **title:** Título del aviso\n",
    "* **description:** Descripción del aviso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cantidad de filas en data: 115149\n",
      "Si ambos tiene la misma cantidad de nulos y estan en las misma filas, al comparar price.isnull() == price_aprox_usd.isnull() y sumar los true deberia dar la mismas filas que el data_original frame: 115149\n",
      "Si ambos tiene la misma cantidad de nulos y estan en las misma filas, al comparar price.isnull() == price_aprox_local_currency.isnull() y sumar los true deberia dar la mismas filas que el data_original frame: 115149\n"
     ]
    }
   ],
   "source": [
    "# Nos fijamos si los nulos son iguales en las columnas de precios. \n",
    "print(\"cantidad de filas en data:\",data.shape[0])\n",
    "print(\"Si ambos tiene la misma cantidad de nulos y estan en las misma filas, al comparar price.isnull() == price_aprox_usd.isnull() y sumar los true deberia dar la mismas filas que el data_original frame:\",(data.price.isnull() == data.price_aprox_usd.isnull()).sum())\n",
    "print(\"Si ambos tiene la misma cantidad de nulos y estan en las misma filas, al comparar price.isnull() == price_aprox_local_currency.isnull() y sumar los true deberia dar la mismas filas que el data_original frame:\",(data.price.isnull() == data.price_aprox_local_currency.isnull()).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Me fijo si los nulos estan en la misma fila en ambas columnas, otra forma de lograr lo mismo que la celda anterior pero de forma diferente\n",
    "set(data.price.isnull().index).issubset(set(data.price_aprox_usd.isnull().index))\n",
    "set(data.price.isnull().index).issubset(set(data.price_aprox_local_currency.isnull().index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:red; font-size:20px;\"> COMENTARIOS</p>\n",
    "\n",
    "<p style=\"color:red; font-size:15px;\"> \n",
    "En lugar de usar issubset usaría ==, subset devuelve True si los elementos del primer set están contenidos en el segundo, pero podría ser más grande el segundo.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLegamos a la conclusión de que las columnas **price**, **price_aprox_local_currency** y **price_aprox_usd** tienen los mismos nulos en las mismas ubicaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"regex\"></a>\n",
    "### Uso de regex para completar los precios en dólares:\n",
    "Se creo la columna **price_dolar** para tener esa columna como refencia del precio y no tener en cuenta las otras 3 del data_original frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de nulos en la culumna price_aprox_usd: 17269\n"
     ]
    }
   ],
   "source": [
    "print(\"Cantidad de nulos en la culumna price_aprox_usd:\",data.price_aprox_usd.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vemos si podemos completar algun price nulo por lo que sale en la descripcion\n",
    "mascara = data.price_aprox_usd.isnull()\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "price_nulo = data[mascara].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\dhdsblend\\lib\\site-packages\\pandas\\core\\indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# vemos el precio que hay en dolares en el titulo de la publicacion para completar nulos, con titulos relleno mas de 2000 precios\n",
    "pat_tit1 = r'((([Uu][\\$][Ss]?)|([Uu][Ss\\$][Dd]{1}))+\\s?(?P<precio>\\d{2,3}[\\.,]*\\d{1,3}))'\n",
    "regex_dol = re.compile(pat_tit1)\n",
    "price_dolar_tit = price_nulo.title.apply(lambda x: regex_dol.search(str(x)))\n",
    "price_dolar_tit.notnull().sum()\n",
    "dolares_punto = price_dolar_tit[price_dolar_tit.notnull()].apply(lambda x: x.group('precio'))\n",
    "dolares_limpios = dolares_punto.apply(lambda x: re.compile(\"\\.\").sub(\"\",x))\n",
    "dolares_limpios_final = dolares_punto.apply(lambda x: re.compile(\"\\.\").sub(\"\",x))\n",
    "data.loc[dolares_limpios.index,'price_dolar'] = dolares_limpios_final.astype(float).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:red; font-size:20px;\"> COMENTARIOS</p>\n",
    "\n",
    "<p style=\"color:red; font-size:15px;\"> \n",
    "No hace falta que usen .copy() después de un apply, ya que por defecto apply devuelve una nueva serie (o dataframe).\n",
    "En lugar de remover los puntos y comas, podrían no haberlos incluido en el grupo de captura\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1665      260.000\n",
       "1666      115.000\n",
       "1667      740.000\n",
       "1669      740.000\n",
       "1677      115.000\n",
       "           ...   \n",
       "50056      235000\n",
       "50057      180000\n",
       "61684     370.000\n",
       "79472     300.000\n",
       "103676     55.000\n",
       "Name: title, Length: 2098, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dolares_punto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.13175103561472526, 0.14997090725929013)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logramos bajar casi 2 puntos porcentuales los nulos \n",
    "data['price_dolar'].isnull().sum()/ data.shape[0], data['price_aprox_usd'].isnull().sum() / data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15171"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quedaron 15171 nulos en la columna price_dolar\n",
    "pd.set_option('display.max_rows',200)\n",
    "data[data['price_dolar'].isnull()].title.sample(200)\n",
    "data['price_dolar'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ambientes\"></a>\n",
    "## Arreglo de columna \"rooms\".\n",
    "Esta columna tiene un gran porcentaje de nulos. A simple vista podemos ver que es posible obtener información para imputarla tomando la columna **description**.<p>\n",
    "Se crea la columna ambientes como refencia a rooms. Y se procede a completarle los valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se crea un data_original frame donde los valores de rooms sean nulos \n",
    "sin_amb = data[data.rooms.isnull()]['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ambientes tipo casa planta baja por pasillo, refaccionado a nuevo, patio grande, con lavadero, living comedor con cocina integrada, artefacto de cocina, alacena, baño completo, y dormitorio. todo en excelente estado, para habitar.no es apto credito aviso publicado por pixel inmobiliario (servicio de páginas web para inmobiliarias).'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x='AMBIENTES TIPO CASA PLANTA BAJA POR PASILLO, REFACCIONADO A NUEVO, PATIO GRANDE, CON LAVADERO, LIVING COMEDOR CON COCINA INTEGRADA, ARTEFACTO DE COCINA, ALACENA, BAÑO COMPLETO, Y DORMITORIO. TODO EN EXCELENTE ESTADO, PARA HABITAR.NO ES APTO CREDITO Aviso publicado por Pixel Inmobiliario (Servicio de Páginas Web para Inmobiliarias).';\n",
    "x.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se prodece a crear varios patrones para encontrar la mayor cantidad posible de datos para rellenar los nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:red; font-size:20px;\"> COMENTARIOS</p>\n",
    "\n",
    "<p style=\"color:red; font-size:15px;\"> \n",
    "Tal vez valdría la pena llevar los campos de texto a lowercase, para no tener que buscar patrones en mayúscula y minúscula. Tambien pueden usar el flag re.IGNORECASE al compilar la regex.\n",
    "Otra cosa que podrían hacer es remover acentos antes de aplicar las regex.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En el patron buscamos los que salen con \"ambientes\" y tambien \"dormitorios\" en las description de las filas que rooms es nulo .\n",
    "pat_amb1 = r'(?P<todo>(?P<numero>\\d{1,2})\\s?[Aa][Mm][Bb])'\n",
    "pat_amb2 = r'(?P<todo>(?P<numero>\\d{1,2})\\s?[Dd][Oo][Rr][Mm])'\n",
    "regex_amb = re.compile(pat_amb1)\n",
    "regex_amb2 = re.compile(pat_amb2)\n",
    "ambientes = sin_amb.apply(lambda x: regex_amb.search(str(x)))\n",
    "dormitorio = sin_amb.apply(lambda x: regex_amb2.search(str(x)))\n",
    "amb_dorm = (ambientes.notnull() & dormitorio.notnull())\n",
    "dorm = dormitorio.notnull() & ~amb_dorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# mediante iloc selecionamos los ambientes y dormitorios que encontramos se los completamos a la columna ambientes. \n",
    "# tenemos cuidado de de que los que coincidan en tener match de ambientes y dormitorios, ponemos solo el match de ambientes \n",
    "data.loc[ambientes[ambientes.notnull()].index,\"ambientes\"] = ambientes[ambientes.notnull()].apply(lambda x: x.group(\"numero\")).copy()\n",
    "data.loc[dorm.index[dorm],\"ambientes\"] = dormitorio[dorm.index[dorm]].apply(lambda x: x.group(\"numero\")).copy()\n",
    "# data.loc[ambientes[ambientes.notnull()].index,\"ambientes\"]\n",
    "# sin_amb.loc[ambientes.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:red; font-size:20px;\"> COMENTARIOS</p>\n",
    "\n",
    "<p style=\"color:red; font-size:15px;\"> \n",
    "OJO CON ESTO:</br>\n",
    "SettingWithCopyWarning: \n",
    "A value is trying to be set on a copy of a slice from a DataFrame.\n",
    "Try using .loc[row_indexer,col_indexer] = value instead\n",
    "</br></br> \n",
    "A veces cuando seleccionamos una parte de un dataframe estamos creando un puntero al dataframe original y a veces estamos creando una copia. Esto depende de cómo hagamos la indexación. Si el método de indexación (por ejemplo anidada) crea una copia del data frame, entonces al modificar esa copia asignándole nuevos valores no vamos a estar modificando el dataframe original. En casos de indexación conflictiva, pandas nos devuelve este warning. Corolario: siempre que aparezca este warning conviene chequear que la asignación se haya producido con éxito.\n",
    "</p>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nos fijamos si con otro patron puedo encontrar mas ambientes para rellenar con otro patron.\n",
    "# encontramos que podemos añadir 57 datos mas, ya que tengo que tener en cuenta que no esten en los otros dos patrones que busque antes\n",
    "patron_amb2 =  r'[Aa][Mm][Bb][Ii][Ee][Nn][Tt][Ee][sS]*\\s?[\\s:]?\\s?(?P<numero>\\d{1,2})'\n",
    "regex_amb1 = re.compile(patron_amb2)\n",
    "ambientes1 = sin_amb.apply(lambda x: regex_amb1.search(str(x)))\n",
    "amb1y2 = ambientes.notnull() & ambientes1.notnull()\n",
    "amb_dorm = ambientes1.notnull() & dormitorio.notnull()\n",
    "amb1_sim_amb= ambientes1.notnull() & ~amb1y2\n",
    "ambientes_otro_pat = amb1_sim_amb & amb_dorm\n",
    "data.loc[ambientes_otro_pat.index[ambientes_otro_pat],\"ambientes\"] = ambientes1[ambientes_otro_pat].apply(lambda x: x.group(\"numero\")).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.283137500108555, 0.6090514610041413)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# con esto nos fijamos cual es el nuevo porcentaje de nulos que tengo y el que tenia. Bajo mas de 30 puntos porcentiales los nulos \n",
    "data.ambientes.isnull().sum() / data.shape[0], data_original.ambientes.isnull().sum() / data_original.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\dhdsblend\\lib\\site-packages\\pandas\\core\\generic.py:5303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "store = data[data.property_type == \"store\"].isnull().copy()\n",
    "data.loc[store.index,\"ambientes\"] = 1\n",
    "data.loc[data.ambientes == 0,\"ambientes\"] = 1\n",
    "data.ambientes = data.ambientes.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"floor\"></a>\n",
    "## Arreglo de columna \"Floor\".\n",
    "Esta columna posee una gran porcentaje de nulos, un 93%. Se podria eliminar pero dado que se cree que puede ser una variable influyentes para derterminar el precio de un departamente se procede a intentar completarla.<p>\n",
    "Se trata de completar los valores faltantes de los pisos de los departamentos.<p>\n",
    "Al igual que en la columna rooms se trata de completar los nulos con varias expresiones regulares diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9351970056188069"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pct_nulos1[\"floor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_tipo_propiedad = data.property_type == ('apartment')\n",
    "tipo_propiedad = data.loc[m_tipo_propiedad,:]\n",
    "\n",
    "m_pisos = tipo_propiedad.floor.isnull()\n",
    "pisos_nulos = tipo_propiedad.loc[m_pisos, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estilo #ºer piso\n",
    "\n",
    "# buscamos pisos en titulo\n",
    "pat_pisos = r\"(?P<pisos>\\d?\\d)(([^A-z]{1,2}?)|([A-z]{2,3})?(\\s?))([pP][iI][sS][oO])\"\n",
    "regexs_piso = re.compile(pat_pisos)\n",
    "pisos_tit = pisos_nulos.title.apply(lambda x: regexs_piso.search(str(x)))\n",
    "pisos_limpio = pisos_tit[pisos_tit.notnull()].apply(lambda x: x.group('pisos')).copy()\n",
    "data.loc[pisos_limpio.index,'floor'] = pisos_limpio.astype(float)\n",
    "\n",
    "\n",
    "# buscamos pisos en description\n",
    "pisos_desc = pisos_nulos.description.apply(lambda x: regexs_piso.search(str(x)))\n",
    "pisos_limpio_2 = pisos_desc[pisos_desc.notnull()].apply(lambda x: x.group('pisos')).copy()\n",
    "# veo cuales ya complete con el titulo para no sobrescribirlos \n",
    "pisos_limpios_iguales = pisos_limpio_2.notnull() & pisos_limpio.notnull()\n",
    "pisos_limpio_2_listo = ~pisos_limpios_iguales & pisos_limpio_2.notnull()\n",
    "data.loc[pisos_limpio_2_listo.index,'floor'] = pisos_limpio_2[pisos_limpio_2_listo].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estilo piso ##\n",
    "# buscamos pisos en titulo \n",
    "pat2_pisos = r\"([pP][iI][sS][oO])(\\s?)(?P<pisos>\\d{1,2})\"\n",
    "regexs2_piso = re.compile(pat2_pisos)\n",
    "pisos_tit_3 = pisos_nulos.title.apply(lambda x: regexs2_piso.search(str(x)))\n",
    "pisos_limpio_3 = pisos_tit_3[pisos_tit_3.notnull()].apply(lambda x: x.group('pisos')).copy()\n",
    "data.loc[pisos_limpio_3.index,'floor'] = pisos_limpio_3.astype(float)\n",
    "\n",
    "# buscamos pisos en description\n",
    "pisos_desc_4 = pisos_nulos.description.apply(lambda x: regexs2_piso.search(str(x)))\n",
    "pisos_limpio_4 = pisos_desc_4[pisos_desc_4.notnull()].apply(lambda x: x.group('pisos')).copy()\n",
    "data.loc[pisos_limpio_4.index,'floor'] = pisos_limpio_4.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estilo PB \n",
    "\n",
    "# buscamos pisos en titulo \n",
    "pat3_pisos = r\"(?P<pisos>[pP][bB])\"\n",
    "regexs3_piso = re.compile(pat3_pisos)\n",
    "pisos_tit_5 = pisos_nulos.title.apply(lambda x: regexs3_piso.search(str(x)))\n",
    "pisos_limpio_5 = pisos_tit_5[pisos_tit_5.notnull()].apply(lambda x: x.group('pisos')).copy()\n",
    "data.loc[pisos_limpio_5.index,'floor'] = pisos_limpio_5\n",
    "\n",
    "# buscamos pisos en description\n",
    "pisos_desc_6 = pisos_nulos.description.apply(lambda x: regexs3_piso.search(str(x)))\n",
    "pisos_limpio_6 = pisos_desc_6[pisos_desc_6.notnull()].apply(lambda x: x.group('pisos')).copy()\n",
    "data.loc[pisos_limpio_6.index,'floor'] = pisos_limpio_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8117656254070813"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pct_nulos(data.floor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\dhdsblend\\lib\\site-packages\\pandas\\core\\frame.py:4153: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n"
     ]
    }
   ],
   "source": [
    "# store_house = data[(data.property_type == \"store\") | (data.property_type == \"house\")]\n",
    "# data.loc[store_house.floor.isnull().index,\"floor\"] = 0\n",
    "data[data.property_type != \"apartment\"].fillna(0,inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6883961117861482, 0.8117656254070813)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pct_nulos(data[data.property_type == \"apartment\"].floor),pct_nulos(data.floor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"m2\"></a>\n",
    "## Columnas referidas a los m² de la propiedad.\n",
    "Se procede a buscar los valores nulos en la columna description a través del uso de expresiones regulares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo el patron y hago la regrex y se la aplico a la descripcion de las filas que no tienen completo la columna surface_covered_in_m2\n",
    "patron_m2_cov = r'(?P<m2>\\d{1,3}[\\.,]?\\d{0,3})\\s?(([Mm]2)|([Mm][Tt][Ss]2?))\\s?[Cc][Uu][Bb]'\n",
    "regex_m2_cov = re.compile(patron_m2_cov)\n",
    "m2_cov_null = data[data.surface_covered_in_m2.isnull()].description\n",
    "cubiertos = m2_cov_null.apply(lambda x: regex_m2_cov.search(str(x)))\n",
    "# obtengo los valores y remplazo las , por . \n",
    "m2_cubiertos = cubiertos[cubiertos.notnull()].apply(lambda x: x.group(\"m2\"))\n",
    "regex_m2_remplazo = re.compile(\",\")\n",
    "m2_cubiertos_limpios = m2_cubiertos[m2_cubiertos.notnull()].apply(lambda x: regex_m2_remplazo.sub(\".\",str(x))).astype(float)\n",
    "# completo los valores faltantes de surface_covered_in_m2 con los que encontre\n",
    "indeces_m2_cubiertos = m2_cubiertos_limpios.notnull().index\n",
    "data.loc[indeces_m2_cubiertos,\"surface_covered_in_m2\"] = m2_cubiertos_limpios.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:red; font-size:20px;\"> COMENTARIOS</p>\n",
    "\n",
    "<p style=\"color:red; font-size:15px;\"> \n",
    "No entendí esta parte de la regex: [Cc][Uu][Bb]. Para qué está? Hace que no encuentren algo como 60m2\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo el patron y hago la regrex y se la aplico a la descripcion de las filas que no tienen completo la columna surface_total_in_m2\n",
    "patron_m2 =  r'(?P<m2>\\d{1,3}[\\.,]?\\d{0,3})\\s?(([Mm]2)|([Mm][Tt][Ss]2?))\\s?[Tt][Oo][Tt]'\n",
    "regex_m2 = re.compile(patron_m2)\n",
    "m2_tot_null = data[data.surface_total_in_m2.isnull()].description\n",
    "totales = m2_tot_null.apply(lambda x: regex_m2.search(str(x)))\n",
    "m2_totales = totales[totales.notnull()].apply(lambda x: x.group(\"m2\"))\n",
    "m2_totales_limpios = m2_totales.apply(lambda x: re.compile(\",\").sub(\".\",str(x))).astype(float)\n",
    "# Completo los valores faltantes de la columna surface_total_in_m2 con lo valores que encontre\n",
    "data.loc[m2_totales_limpios.notnull().index,\"surface_total_in_m2\"] = m2_totales_limpios.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analizando posibles acciones con las columnas price_usd_per_m2 y price_per_m2.\n",
    "1. Se revisa de que tipo de moneda son los datos nulos.\n",
    "2. Se trata de determinar si las columnas **price_usd_per_m2** y **price_per_m2** hacen refencia al precio por metro cuadrado cubierto o total.\n",
    "3. Se realiza la comprobacion si hay algunos datos en **price_per_m2** que esten en dolares y no en pesos.\n",
    "4. Dada la complejedad de las columnas **price_usd_per_m2** y **price_per_m2** se procede a crear dos nuevas columnas, que esten expresadas en dolares y que contenga los precios por metro cuadrado cubiertos y totales por separado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "USD    21067\n",
       "ARS     2787\n",
       "Name: currency, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data[data.price_usd_per_m2.isnull() & data.price_per_m2.notnull()][[\"currency\",\"price_per_m2\"]][:50]\n",
    "data[data.price_usd_per_m2.isnull() & data.price_per_m2.notnull()][\"currency\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se trata de verificar de donde sale el precio por metro cuadrado \n",
    "preciom2_total_pesos = data.price_aprox_local_currency / data.surface_total_in_m2\n",
    "preciom2_total_usd = data.price_aprox_usd / data.surface_total_in_m2\n",
    "preciom2_cov_pesos = data.price_aprox_local_currency / data.surface_covered_in_m2\n",
    "preciom2_cov_usd = data.price_aprox_usd / data.surface_covered_in_m2\n",
    "preciom2_total = data.price / data.surface_total_in_m2\n",
    "preciom2_total_cov = data.price / data.surface_covered_in_m2\n",
    "preciom2_total_price_dolar = data.price_dolar / data.surface_total_in_m2\n",
    "preciom2_cov_price_dolar = data.price_dolar / data.surface_covered_in_m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cantidad de precios iguales entre precio por m2 total de la columna price y price_per_m2\n",
      " 20923\n",
      "cantidad de precios iguales entre precio por m2 cubierto de la columna price y price_per_m2\n",
      " 85042\n",
      "cantidad de precios iguales entre precio por m2 total de la columna price y price_usd_per_m2\n",
      " 58348\n",
      "cantidad de precios iguales entre precio por m2 cubierto de la columna price y price_usd_per_m2\n",
      " 18776\n",
      "cantidad de precios iguales entre precio por m2 total en pesos y price_per_m2\n",
      " 76\n",
      "cantidad de precios iguales entre precio por m2 cubierto en pesos y price_per_m2\n",
      " 276\n",
      "cantidad de precios iguales entre precio por m2 total en dolares y price_per_m2\n",
      " 18890\n",
      "cantidad de precios iguales entre precio por m2 cubiert en dolares y price_per_m2\n",
      " 75155\n",
      "cantidad de precios iguales entre precio por m2 total en dolares y price_usd_per_m2 \n",
      " 66318\n",
      "cantidad de precios iguales entre precio por m2 cubiert en dolares y price_usd_per_m2 \n",
      " 20962\n",
      "cantidad entradas no nulos en data_original.price_per_m2\n",
      " 85042\n",
      "cantidad entradas no nulos en data_original.price_usd_per_m2\n",
      " 66318\n"
     ]
    }
   ],
   "source": [
    "print(\"cantidad de precios iguales entre precio por m2 total de la columna price y price_per_m2\\n\",(round(preciom2_total,-2) == round(data.price_per_m2,-2)).sum())\n",
    "print(\"cantidad de precios iguales entre precio por m2 cubierto de la columna price y price_per_m2\\n\",(round(preciom2_total_cov,-2) == round(data.price_per_m2,-2)).sum())\n",
    "print(\"cantidad de precios iguales entre precio por m2 total de la columna price y price_usd_per_m2\\n\",(round(preciom2_total,-2) == round(data.price_usd_per_m2,-2)).sum())\n",
    "print(\"cantidad de precios iguales entre precio por m2 cubierto de la columna price y price_usd_per_m2\\n\",(round(preciom2_total_cov,-2) == round(data.price_usd_per_m2,-2)).sum())\n",
    "print(\"cantidad de precios iguales entre precio por m2 total en pesos y price_per_m2\\n\",(round(preciom2_total_pesos,-2) == round(data.price_per_m2,-2)).sum())\n",
    "print(\"cantidad de precios iguales entre precio por m2 cubierto en pesos y price_per_m2\\n\",(round(preciom2_cov_pesos,-2) == round(data.price_per_m2,-2)).sum())\n",
    "print(\"cantidad de precios iguales entre precio por m2 total en dolares y price_per_m2\\n\",(round(preciom2_total_usd,-2) == round(data.price_per_m2,-2)).sum())\n",
    "print(\"cantidad de precios iguales entre precio por m2 cubiert en dolares y price_per_m2\\n\",(round(preciom2_cov_usd,-2) == round(data.price_per_m2,-2)).sum())\n",
    "print(\"cantidad de precios iguales entre precio por m2 total en dolares y price_usd_per_m2 \\n\",(round(preciom2_total_usd,-2) == round(data.price_usd_per_m2,-2)).sum())\n",
    "print(\"cantidad de precios iguales entre precio por m2 cubiert en dolares y price_usd_per_m2 \\n\",(round(preciom2_cov_usd,-2) == round(data.price_usd_per_m2,-2)).sum())\n",
    "print(\"cantidad entradas no nulos en data_original.price_per_m2\\n\",data.price_per_m2.notnull().sum())\n",
    "print(\"cantidad entradas no nulos en data_original.price_usd_per_m2\\n\",data.price_usd_per_m2.notnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable de precio por metros cuadrado creadas a partir de la columna price y de los metros cuadrados CUBIERTOS, es igual al la columna price_per_m2. Con esto se puede apreciar que gran mayoria de los valores que se encuentran en la columna price_per_m2 son en DOLARES y se refiere al precio por metros cuadrado CUBIERTOS.<p>\n",
    "Ademas la columna price_usd_per_m2 contiene el precio por metro cuadrado TOTALES.<p>\n",
    "Dada la complejidad de estas dos columnas se procede a crea 2 columnas nuevas:<p>\n",
    "* pricem2_covered_usd: Contiene el precio por metro cuadrado cubierto, se obtiene de dividir la columna price_dolar por la columna data.surface_covered_in_m2.\n",
    "* pricem2_total_usd: Contiene el precio por metro cuadrado totales, se obtiene de dividir la columna price_dolar por la columna data.surface_total_in_m2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\dhdsblend\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "x=data.price_dolar / data.surface_covered_in_m2\n",
    "data['pricem2_total_usd']=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\dhdsblend\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\dhdsblend\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "data[\"pricem2_covered_usd\"] = (data.price_dolar / data.surface_covered_in_m2).copy()\n",
    "data[\"pricem2_total_usd\"] = (data.price_dolar / data.surface_total_in_m2).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cantidad de nulos en price_per_m2: 30107\n",
      "cantidad de nulos en price_usd_per_m2: 48831\n",
      "Cantidad de nulos en columna pricem2_covered_usd: 27810\n",
      "Cantidad de nulos en columna pricem2_total_usd: 46346\n"
     ]
    }
   ],
   "source": [
    "print(\"cantidad de nulos en price_per_m2:\",data.price_per_m2.isnull().sum())\n",
    "print(\"cantidad de nulos en price_usd_per_m2:\",data.price_usd_per_m2.isnull().sum())\n",
    "print(\"Cantidad de nulos en columna pricem2_covered_usd:\",data[\"pricem2_covered_usd\"].isnull().sum())\n",
    "print(\"Cantidad de nulos en columna pricem2_total_usd:\",data[\"pricem2_total_usd\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logramos crear dos columnas del precio por m2 muchos claras y en dolares por lo que ya no hay variación en el tipo de moneda usada para medir el precio. Ademas bajamos la cantidad de nulos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"baños\"></a>\n",
    "## Baños"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable(patrones,grupo,nombre,df,donde):\n",
    "    for patron in patrones:\n",
    "        regex = re.compile(patron,re.IGNORECASE)\n",
    "        match = df[donde].apply(lambda x: regex.search(str(x)))\n",
    "        listo = match[match.notnull()].apply(lambda x: x.group(grupo).lower())\n",
    "        df.loc[listo.index,nombre] = listo\n",
    "    print(\"Cantidad de propiedad con baños en la descripción\",df[nombre].notnull().sum())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\dhdsblend\\lib\\site-packages\\pandas\\core\\indexing.py:845: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de propiedad con baños en la descripción 508\n",
      "Cantidad de propiedad con baños en la descripción 11938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\dhdsblend\\lib\\site-packages\\pandas\\core\\generic.py:6746: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\dhdsblend\\lib\\site-packages\\pandas\\core\\generic.py:6245: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "patrones_baños = [r\"[bv]año[s]*[:\\s]*(?P<baños>\\d{1})\",r\"(?P<baños>\\d{1})[\\s]*[bv]años\",r\"(?P<baños>dos|tres|cuatro|cinco|seis|siete)\\s*[bv]año[s]*\"]\n",
    "# patrones_baños = [r\"(?P<baños>baño[s]*)\"]\n",
    "data = variable(patrones_baños,\"baños\",\"Baños\",data,\"title\")\n",
    "data = variable(patrones_baños,\"baños\",\"Baños\",data,\"description\")\n",
    "data.Baños.replace([\"dos\",\"tres\",\"cuatro\",\"cinco\",\"seis\",\"siete\"],[2,3,4,5,6,7],inplace = True)\n",
    "data.Baños.fillna(1,inplace=True)\n",
    "data.Baños = data.Baños.astype(int)\n",
    "data.Baños.replace([0],[1],inplace = True)\n",
    "data = data[data.Baños < 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"amenities\"></a>\n",
    "## Amenities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amenities(patrones,nombres,data):\n",
    "    dummy = pd.DataFrame(dtype=int)\n",
    "    for i in range(len(patrones)):\n",
    "        regex = re.compile(patrones[i],flags=re.IGNORECASE)\n",
    "        match = data.apply(lambda x: regex.search(str(x)))\n",
    "        dummy[nombres[i]] = match.apply(lambda x: 0 if x is None else 1)\n",
    "        print(\"Cantidad de lugares con {x}: {n}\".format(x=nombres[i],n=dummy[nombres[i]].sum()))\n",
    "    return dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de lugares con Parrilla: 38900\n",
      "Cantidad de lugares con Quincho: 20215\n",
      "Cantidad de lugares con Balcon: 40053\n",
      "Cantidad de lugares con Patio: 34200\n",
      "Cantidad de lugares con Lavadero: 37031\n",
      "Cantidad de lugares con Baulera: 10247\n",
      "Cantidad de lugares con Gimnasio: 8577\n",
      "Cantidad de lugares con Seguridad: 12411\n",
      "Cantidad de lugares con Barrio_Cerrado: 2985\n",
      "Cantidad de lugares con Calefaccion: 17628\n",
      "Cantidad de lugares con Terraza: 25912\n",
      "Cantidad de lugares con Sauna: 3721\n",
      "Cantidad de lugares con Pileta: 31000\n",
      "Cantidad de lugares con Cochera: 51213\n",
      "Cantidad de lugares con Jacuzzi: 3649\n",
      "Cantidad de lugares con Aire_Acondicionado: 10653\n",
      "Cantidad de lugares con Amueblado: 1212\n",
      "Cantidad de lugares con Estrenar: 10076\n"
     ]
    }
   ],
   "source": [
    "descripcion = data[data.description.notnull()].description\n",
    "patrones_amenities = [r\"(pa[r]{1,2}i[l]{1,2})|(a[sz]ador)\",r\"(quincho)|(sal[oó]n)|(\\ssum\\s)\",r\"balc[óo]n\",r\"(patio)|(jard[ií]n)\",r\"la[bv]adero\",r\"[bv]aulera\",r\"(gimna[sc]io)|gym\",r\"(seguridad)|([vb]igilancia)\",r\"(countr[yi])|(barrio\\scer[r]{0,1}ado)|(barrio pri[vb]ado)\",r\"(calefacci[oó]n)|(estufa)\",r\"te[r]{1,2}a[sz]a\",r\"sauna\",r\"(pileta)|(pi[s]{0,1}cina)\",r\"(cochera)|(gara[gj]e)|(estacionamiento)\",r\"(jacuzzi)|(jacusi)\",r\"aire\\sacondi[sc]ionado\",r\"(amueblado)|(amoblado)\",r\"estrenar\"]\n",
    "nombres_amenities = [\"Parrilla\",\"Quincho\",\"Balcon\",\"Patio\",\"Lavadero\",\"Baulera\",\"Gimnasio\",\"Seguridad\",\"Barrio_Cerrado\",\"Calefaccion\",\"Terraza\",\"Sauna\",\"Pileta\",\"Cochera\",\"Jacuzzi\",\"Aire_Acondicionado\",\"Amueblado\",\"Estrenar\"]\n",
    "data_amenities = amenities(patrones_amenities,nombres_amenities,descripcion)\n",
    "data = data.join(data_amenities,how=\"left\")\n",
    "data[[\"Parrilla\",\"Quincho\",\"Balcon\",\"Patio\",\"Lavadero\",\"Baulera\",\"Gimnasio\",\"Seguridad\",\"Barrio_Cerrado\",\"Calefaccion\",\"Terraza\",\"Sauna\",\"Pileta\",\"Cochera\",\"Jacuzzi\",\"Aire_Acondicionado\",\"Amueblado\",\"Estrenar\"]].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se eliminan regristros erroneos\n",
    "Hay algunos registros que comprenden fondos de comercio y podria afectar a las regresiones. Se procede a quitarlos del data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de lugares con fondo: 165\n"
     ]
    }
   ],
   "source": [
    "fondos_de_comercio = amenities([r\"fondo de comercio\"],[\"fondo\"],data.description)\n",
    "data = data[fondos_de_comercio.fondo != 1].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporto los datos para hacer el desafio 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel(\"data_set_limpio.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114884, 52)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"graficos\"></a>\n",
    "## Graficando los Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables numericas\n",
    "<a id=\"numericas\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Porcentaje de nulos\n",
    "Se realizo un grafico de barras para ver cuantos nulos habia antes y cuantos hay ahora. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.pct_nulos(df)>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pct_nulos_ahora= data.isnull().sum()/data.shape[0]\n",
    "pct_nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'function' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-cc298a98e6dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpct_nulos_ahora\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"floor_antes\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpct_nulos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"floor\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpct_nulos_ahora\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"price_usd_per_m2_antes\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpct_nulos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"price_usd_per_m2\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpct_nulos_ahora\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"floor_antes\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpct_nulos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"floor\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpct_nulos_ahora\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"latlon_antes\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpct_nulos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"lat-lon\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnulos_graf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpct_nulos_ahora\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"price_aprox_usd\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"price_dolar\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"rooms\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"ambientes\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"floor_antes\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"floor\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"price_usd_per_m2_antes\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"pricem2_total_usd\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"latlon_antes\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"lat-lon\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Nulos\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'function' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "pct_nulos_ahora[\"floor_antes\"] = pct_nulos[\"floor\"]\n",
    "pct_nulos_ahora[\"price_usd_per_m2_antes\"] = pct_nulos[\"price_usd_per_m2\"]\n",
    "pct_nulos_ahora[\"floor_antes\"] = pct_nulos[\"floor\"]\n",
    "pct_nulos_ahora[\"latlon_antes\"] = pct_nulos[\"lat-lon\"]\n",
    "nulos_graf = pd.DataFrame(pct_nulos_ahora[[\"price_aprox_usd\",\"price_dolar\",\"rooms\",\"ambientes\",\"floor_antes\",\"floor\",\"price_usd_per_m2_antes\",\"pricem2_total_usd\",\"latlon_antes\",\"lat-lon\"]]*100,columns=[\"Nulos\"])\n",
    "nulos_graf[\"variables\"] = [\"price_dolar\",\"price_dolar\",\"rooms\",\"rooms\",\"floor\",\"floor\",\"price_usd_per_m2\",\"price_usd_per_m2\",\"lat-lon\",\"lat-lon\"]\n",
    "nulos_graf[\"cuando\"] = [\"Antes\",\"Despues\",\"Antes\",\"Despues\",\"Antes\",\"Despues\",\"Antes\",\"Despues\",\"Antes\",\"Despues\"]\n",
    "nulos_graf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultado de la limpieza de los valores nulos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "grafico_nulos = sns.barplot(x=\"variables\", y=\"Nulos\", hue=\"cuando\", data= nulos_graf)\n",
    "grafico_nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En las columnas que mas se logro bajar los nulos fue en Rooms y Floor.\n",
    "En las demas columns se logro bajar mas de 2% de los nulos en total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pairplot para ver la relacion entre las variables numericas que pueden afectar al precio\n",
    "Se le aplica logaritmo a la columna **price_dolar** para acortar la dispersión entre los datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairplot = data[['price_dolar','surface_total_in_m2','surface_covered_in_m2','ambientes']].copy()\n",
    "pairplot.dropna(axis=0,how=\"all\",subset=[\"price_dolar\"],inplace=True)\n",
    "pairplot.drop(pairplot[pairplot.price_dolar <= 0].index,inplace=True)\n",
    "pairplot[\"price_dolar\"] = np.log(pairplot[\"price_dolar\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairplot.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a eliminar los outliers para que no ensucien el grafico y poder ver bien la distribución de los mismos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lim_inf(serie):\n",
    "    q1 = serie.quantile(q=0.25)\n",
    "    q3 = serie.quantile(q=0.75)\n",
    "    lim_inf = q1 - (q3-q1) * 1.5\n",
    "    return lim_inf\n",
    "def lim_sup(serie):\n",
    "    q1 = serie.quantile(q=0.25)\n",
    "    q3 = serie.quantile(q=0.75)\n",
    "    lim_sup= q3 + (q3-q1)*1.5\n",
    "    return lim_sup\n",
    "pairplot1 = pairplot[(pairplot.ambientes > lim_inf(pairplot.ambientes)) & (pairplot.ambientes <= lim_sup(pairplot.ambientes))]\n",
    "pairplot2 = pairplot1[(pairplot1.surface_total_in_m2 >= lim_inf(pairplot1.surface_total_in_m2)) & (pairplot1.surface_total_in_m2 <= lim_sup(pairplot1.surface_total_in_m2))]\n",
    "pairplot3 = pairplot2[(pairplot2.surface_covered_in_m2 >= lim_inf(pairplot2.surface_covered_in_m2)) & (pairplot2.surface_covered_in_m2 <= lim_sup(pairplot2.surface_covered_in_m2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafico_pair_plot = sns.pairplot(data=pairplot3)\n",
    "grafico_pair_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No se logra ver una correlacion fuerte de **price_dolar** con alguna de las variables. Eso tambien se vio en la matriz de correlación.<p>\n",
    "Ademas en las diagonales se puede ver la distribución de cada variables con una bar plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables categoricas\n",
    "<a id=\"categoricas\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grafico de Torta para state_name\n",
    "Se realizo un grafico de torta para ver como estab distribuidas las propiedades en los diferentes valores de **state_name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_name_count = data.state_name.value_counts()\n",
    "resto = state_name_count[8:].sum()\n",
    "state_name_count.drop(index=state_name_count[8:].index,inplace=True)\n",
    "state_name_count[\"Resto\"] = resto\n",
    "state_name_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(8, 6))\n",
    "ax1.pie(x= state_name_count,labels=state_name_count.index,autopct='%1.1f%%',shadow=True)\n",
    "ax1.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede apreciar que gran parte de las propiedades se encuentra en Capital Federal, Bs.As. G.B.A. Zona Norte y Bs.As. G.B.A. Zona Sur. Mas de un 50% de los datos se encuentra entre estas 3 ubicaciones "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grafico de Torta para property_type\n",
    "Se hizo para saber el porcentaje de cada propiedad que hay en el data_original set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipo_propiedad = data[[\"price_dolar\",\"property_type\"]]\n",
    "torta = tipo_propiedad.property_type.value_counts()\n",
    "fig, ax1 = plt.subplots(figsize=(8, 6))\n",
    "ax1.pie(x= torta,explode=(0.05,0,0,0),labels=torta.index,autopct='%1.1f%%',shadow=True)\n",
    "ax1.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver que un 57% de los datos son referidos a departamentes, por lo que la columnas floor que completamos puede ayudar a determinar el precio de este tipo de propiedad. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Violin plot para property_type y price_dolar\n",
    "Se realizo un violin plot para ver la distribucion del precio segun el tipo de vivienda. Ademas se agrega dentro del mismo un box plot<p>\n",
    "Ya que el precio es una variable muy dispersa se procede a graficar el logaritmo del precio en dolares de la propiedad. Con esto logramos achicar la dispersión de los datos y ver mas claramente la distribución de los mismos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "fig = go.Figure()\n",
    "for tipo in tipo_propiedad.property_type.unique():\n",
    "    fig.add_trace(go.Violin(x=tipo_propiedad[\"property_type\"][tipo_propiedad.property_type == tipo],\\\n",
    "                            y=np.log(tipo_propiedad[\"price_dolar\"][tipo_propiedad.property_type == tipo]),\\\n",
    "                            name = tipo,\\\n",
    "                            box_visible=True\n",
    "                           ))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de el violin plot se puede ver la distribución de los datos.<br>\n",
    "<p>Se puede ver que <b>PH , apartment y House</b> tienen muchos outliers, esto se logra ver con el box plot. Se puede concluir que cuentan con bastante dispersión en sus datos.</p>\n",
    "En cambio, con <b>store</b> se puede ver que no contiene muchos outliers, ademas las datos parecen seguir mas una distribución normal y estan mas centrados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
